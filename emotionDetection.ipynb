{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc60bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Bidirectional\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import cross_val_score \n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d95937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing extra rows: (7651, 2)\n",
      "(7564, 2)\n"
     ]
    }
   ],
   "source": [
    "#step2:load the dataset\n",
    "df = pd.read_csv(r\"D:\\jangoProject\\nlp\\EmotionDetection\\isear.csv\")\n",
    "print('Before removing extra rows:', df.shape)\n",
    "\n",
    "# The isear.csv contains rows with value 'No response' in the second column,\n",
    "# so we need to remove such rows.\n",
    "\n",
    "# Normalize the text by stripping whitespace and converting to lowercase\n",
    "df.drop(df[df.iloc[:,1].astype(str).str.lower().str.contains(r'no\\s*response', na=False)\n",
    "   ].index,\n",
    "    inplace=True\n",
    ")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4b08bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['every', 'time', 'i', 'imagine', 'that', 'someone', 'i', 'love', 'or', 'i', 'could', 'contact', 'a', 'serious', 'illness', 'even', 'death']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])  # Disable unused pipeline components to speed up\n",
    "\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [\n",
    "        token.text.lower()\n",
    "        for token in doc\n",
    "        if not token.is_punct and not token.is_space\n",
    "        # optionally uncomment to remove stopwords:\n",
    "        # and not token.is_stop\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenize_text function to the text column (second column at index 1)\n",
    "tokenizeText = df.iloc[:, 1].apply(tokenize_text)\n",
    "\n",
    "# Convert the list of token lists into a pandas Series (optional, but good for alignment with DataFrame)\n",
    "tokenizeText = pd.Series(tokenizeText)\n",
    "\n",
    "print(tokenizeText[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc96a8d",
   "metadata": {},
   "source": [
    "step3:This section converts pre-tokenized sentences back into plain text strings so that Keras's Tokenizer can process them. The tokenizer is then fitted on this text corpus to create a vocabulary mapping words to integer indices. Finally, each text is converted to a sequence of integers representing token IDs, which can be fed into downstream models such as embedding layers or LSTMs. This step bridge tokenization and numerical encoding for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c54ad65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# Convert token lists back to strings\n",
    "texts = tokenizeText.apply(lambda tokens: ' '.join(tokens)).tolist()\n",
    "\n",
    "# Initialize and fit tokenizer on texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "\n",
    "# Convert texts to integer sequences\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "052eddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7564, 100)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the integer sequences to a fixed length (100 tokens) using post-padding.\n",
    "# This ensures all input sequences have the same length for batch processing.\n",
    "# The result is a 2D NumPy array suitable as input to embedding layers and LSTM models.\n",
    "X_train_pad =pad_sequences(sequences,maxlen=100,padding='post')\n",
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d9658f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6051, 100)\n",
      "(1513, 100)\n",
      "(6051, 7)\n",
      "(1513, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = X_train_pad  # padded input sequences (numpy array)\n",
    "\n",
    "# Extract labels column, convert to numpy array and reshape to 2D for encoder\n",
    "labels = df.iloc[:, 0].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n",
    "\n",
    "# Fit and transform labels\n",
    "y = encoder.fit_transform(labels)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "print(X_train.shape)  # (num_train_samples, 100)\n",
    "print(X_test.shape)   # (num_test_samples, 100)\n",
    "print(y_train.shape)  # (num_train_samples, num_classes)\n",
    "print(y_test.shape)   # (num_test_samples, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "431360a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mina\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_5             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_25                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_26                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_5             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_25                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_26                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, SpatialDropout1D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Fix random seed for reproducibility (optional)\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 50\n",
    "max_length = 100\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "    # Build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "551dcb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 779ms/step - accuracy: 0.1614 - loss: 2.0422 - val_accuracy: 0.2789 - val_loss: 1.9415\n",
      "Epoch 2/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 754ms/step - accuracy: 0.3610 - loss: 1.6790 - val_accuracy: 0.2472 - val_loss: 1.8696\n",
      "Epoch 3/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 581ms/step - accuracy: 0.5249 - loss: 1.3373 - val_accuracy: 0.3589 - val_loss: 1.7426\n",
      "Epoch 4/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 684ms/step - accuracy: 0.6038 - loss: 1.1130 - val_accuracy: 0.5109 - val_loss: 1.5080\n",
      "Epoch 5/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 613ms/step - accuracy: 0.6886 - loss: 0.9141 - val_accuracy: 0.5169 - val_loss: 1.3662\n",
      "Epoch 6/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 680ms/step - accuracy: 0.7381 - loss: 0.7691 - val_accuracy: 0.5043 - val_loss: 1.4232\n",
      "Epoch 7/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 831ms/step - accuracy: 0.7810 - loss: 0.6891 - val_accuracy: 0.5116 - val_loss: 1.5782\n",
      "Epoch 8/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 830ms/step - accuracy: 0.8050 - loss: 0.6070 - val_accuracy: 0.5221 - val_loss: 1.7307\n",
      "Epoch 9/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 828ms/step - accuracy: 0.8342 - loss: 0.5233 - val_accuracy: 0.4845 - val_loss: 1.8985\n",
      "Epoch 10/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 675ms/step - accuracy: 0.8427 - loss: 0.4892 - val_accuracy: 0.5017 - val_loss: 1.8986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Setup early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Fit model with validation on test data (consider splitting train for validation if desired)\n",
    "history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=30,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "33d7a27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.5297 - loss: 1.3270\n",
      "Test loss: 1.3846439123153687, Test accuracy: 0.5102445483207703\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "18ae8358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "[['fear']\n",
      " ['anger']\n",
      " ['sadness']\n",
      " ...\n",
      " ['disgust']\n",
      " ['shame']\n",
      " ['guilt']]\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(y_test)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1371715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step\n"
     ]
    }
   ],
   "source": [
    "y=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d077368",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7980cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Predicted Emotion: sadness\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def predict_emotion(text, model, tokenizer, encoder, max_length=100):\n",
    "   \n",
    "\n",
    "    # Convert text to integer sequence and pad\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Predict class probabilities\n",
    "    probs = model.predict(padded)\n",
    "\n",
    "    # Get index of max probability class\n",
    "    class_idx = np.argmax(probs, axis=1)[0]\n",
    "\n",
    "    # Decode class index to original label\n",
    "    label = encoder.categories_[0][class_idx]\n",
    "\n",
    "    return label\n",
    "\n",
    "# Example usage:\n",
    "predicted_label = predict_emotion(\"When I think about the short time that we live and relate it to the periods of my life when I think that I did not use this  \", model, tokenizer, encoder)\n",
    "print(\"Predicted Emotion:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "83224f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "model.save('model.h5')\n",
    "\n",
    "# Saving tokenizer and encoder with pickle\n",
    "import pickle\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "with open('encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# Loading for predict.py\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "with open('encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
